---
author: Yan Wang
categories:
  - 论文
comments: true
date: 2017-06-13 21:21:21 -0700
tags:
  - 论文
  - 技术
  - 科研
title: EMNLP 2017 阅读笔记
url: /2017/08/19/emnlp17/
---


录用论文列表：[EMNLP 2017 Accepted papers](http://emnlp2017.net/accepted-papers.html)

## Importance sampling for unbiased on-demand evaluation of knowledge base population

兴趣点：Importance sampling, Percy Liang, Christopher D. Manning


## Supervised Learning of Universal Sentence Representations from Natural Language Inference Data

兴趣点：Sentence Representations, Antoine Bordes

## Bringing Structure into Summaries: Crowdsourcing a Benchmark Corpus of Concept Maps

兴趣点：Crowdsourcing, Benchmark Corpus

这篇文章跟想象的不太一样，主要涉及的任务是 Multi-document Summarization, 其中的 Concept Map 是一种表示文章内容的手段。Concept Map 用来表示一批相关文档中的主要内容，是一个大小有约束的连通图，节点是文中提到的概念，边是概念间的关系，这里的“概念”和“关系”都是用词的序列来表示（不连接到KG）。一条边加上连接的两个点，就可以构成一个陈述句了。

多文本摘要的传统标注非常昂贵，特别是 Concept Map 则对一般标注者不友好，只能由专家来标注（更昂贵）。本文通过标注 Concept Map 中的边（其实是陈述句）的重要性，来对特定话题的若干陈述进行排序（标注者不需要通读所有文章），得到最终的 Concept Map。

这篇文章后面的部分主要讲解如何设置标注任务，以及对于标注结果可靠性、一致性的分析，介绍了很多细节。就没仔细看了。如果想更好地利用廉价的人工标注（区别于专家标注），应该能从本文中找到不少启发。

## Fine Grained Citation Span for References in Wikipedia

兴趣点：Wikipedia

这篇文章提出了一个有趣的问题，给一篇维基百科的文章正文和引用，如何构建一个函数，能给每一个引用找到所覆盖的范围（citation span）。文章列举了一些相关方法，比如在学术文献上的引用分析，以及在 IR 领域用到的检测 citation span 的方法，但这些方法的结果只能到句子这个粒度，不能再进一步给出更细粒度的结果（所以本文标题突出了 Fine Grained）。

在方法上面，本文用 sequence classification 来对检测 citation span 的任务进行建模，使用了 CRF 配合一系列特征（有大量篇幅介绍特征，此处略过），对于每一个引用，输入一个由句子片段 (fragment) 组成的序列，输出哪些 fragment 被该引用所涵盖。在维基百科上人工标注了一批数据作为 ground truth，然后实验显示本文提出的方法比 baseline 要好，后面还有一些关于鲁棒性、特征、错误样例的分析。作者也承认， baseline 方法只能标到句子粒度的结果所以在评测中吃亏。

本文内容丰富、格式规矩、语言流畅，特别像大作业报告。第一作者在六年来发了30+篇文章，但是 topic 都非常飘忽不定。

## Learning Generic Sentence Representations Using Convolutional Neural Networks

兴趣点：Sentence Representations

模型还挺 fancy 的（意思是我没太看懂细节）。先是一个 CNN-LSTM 的 encoder-decoder 结构，用 CNN 做 encoder，LSTM 做 decoder；得到 sentence embedding 之后，再在上面加一层 (hierarchical) LSTM 来捕获跨 sentence 的信息。这几个架构都是从前人那里学来的，没太看出来本文在网络结构方面的原创性。不过文章给出了非常详细的 formulation 和实验介绍，在一些 NLP 经典任务上对比了包括本文提出方法在内的 general sentence representation 和一些对特定任务设计的方法，结果大致说明在 general sentence representation 上本文的方法效果是最好的，但还是比不上为特定任务专门设计的方法。

本文算是一个小综述，把类似方法的文章都提了一遍（有的还不止一遍），有些引文的引用还挺高的，或许值得一看。至于本文的方法，感觉有点鸡肋，用一个相对复杂的结构获取一种通用的表示，估计不太适合工业应用吧。

## MinIE: Minimizing Facts in Open Information Extraction

兴趣点：Open IE

## Multi-Grained Chinese Word Segmentation

兴趣点： Multi-Grained

## Entity Linking via Joint Encoding of Types, Descriptions, and Context

兴趣点：Entity Linking, Types

## Neural Semantic Parsing with Type Constraints for Semi-Structured Tables

兴趣点：Type Constraints

这篇文章设计了一个端到端的神经网络模型，来处理基于维基百科表格的问答任务。网络结构比较复杂，大致上是一个基于 BiLSTM 的 encoder-decoder 架构，对 entity 进行 embedding，其中包括来了 entity linking （这是文章声称的相比前人的重要改进）以及 entity 的类型信息。输出是某种考虑类别的形式语言，文章声称的第二个贡献是，在生成输出语言的时候不需要添加隐变量。然而没太多背景知识，不知道这个语言如何转化为最终的答案。

数据集用了 WikiTableQuestions，一万多训练数据和四千条测试数据，单个模型性能可以到 43.3% accuracy。文章提到有个基于 Freebase 的 QA 数据集，样例更多而且涉及 domain 更广，但问题太简单所以没有采用。

在错误分析中，文章提到几种大的错误类别：(1) 从若干选项中选一个答案，比如 “Who had more silvers, Colombia or The Bahamas”，我猜可能是因为类别一样的情况确实比较难；(2) Entity linking 错误，这个没办法。其他还有些错误原因，比如答案只是一个 Cell 内容的一部分，还有一些没太看懂的原因。

## End-to-end Neural Coreference Resolution

兴趣点：Coreference Resolution

## Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension

兴趣点：Xianpei Han

## Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach

兴趣点：Relation Extraction, Jiawei Han

## Shortest-Path Graph Kernels for Document Similarity

兴趣点：Document Similarity

## Learning to select data for transfer learning with Bayesian Optimization

兴趣点：Transfer learning


## Entity Linking for Queries by Searching Wikipedia Sentences

兴趣点：Entity Linking, Wikipedia

## Identifying Semantic Edit Intentions from Revisions in Wikipedia

兴趣点：Wikipedia Revisions

作者 [Diyi Yang](http://www.cs.cmu.edu/~diyiy/) 在 ICWSM 2016 上还发过一篇相关的文章 *Who does What: Editor Role Identification in Wikipedia*，两篇文章应该连在一起看。内容领域不太熟悉，感觉应该属于 Social Computing 的范畴，大致扫了一眼，以后需要还可以详细读。在 ICWSM 2016  的那篇文章里，作者延伸了前人对于维基百科不同编辑者的角色的分类，为各种角色下了非常直观的定义，并且跟不同的编辑行为联系在一起，构建分类器来判断编辑者所属的角色。在 EMNLP 2017 的这篇文章里，作者提出 revision 是有意图的，并且构建数据集和模型来对每一个 revision 的意图进行分类。这两篇文章分别从编辑者和编辑行为的角度出发，探讨了关于维护维基百科文章质量、新贡献者留存等问题。

## Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics

兴趣点：Word Representations




