---
author: Yan Wang
date: 2017-06-13 21:21:21 -0700
layout: post
title: EMNLP 2017 阅读笔记
categories: [论文]
comments: true
tags:
-  论文
-  技术
-  科研
---

录用论文列表：[EMNLP 2017 Accepted papers](http://emnlp2017.net/accepted-papers.html)

## Importance sampling for unbiased on-demand evaluation of knowledge base population

兴趣点：Importance sampling, Percy Liang, Christopher D. Manning


## Supervised Learning of Universal Sentence Representations from Natural Language Inference Data

兴趣点：Sentence Representations, Antoine Bordes

## Bringing Structure into Summaries: Crowdsourcing a Benchmark Corpus of Concept Maps

兴趣点：Crowdsourcing, Benchmark Corpus

这篇文章跟想象的不太一样，主要涉及的任务是 Multi-document Summarization, 其中的 Concept Map 是一种表示文章内容的手段。Concept Map 用来表示一批相关文档中的主要内容，是一个大小有约束的连通图，节点是文中提到的概念，边是概念间的关系，这里的“概念”和“关系”都是用词的序列来表示（不连接到KG）。一条边加上连接的两个点，就可以构成一个陈述句了。

多文本摘要的传统标注非常昂贵，特别是 Concept Map 则对一般标注者不友好，只能由专家来标注（更昂贵）。本文通过标注 Concept Map 中的边（其实是陈述句）的重要性，来对特定话题的若干陈述进行排序（标注者不需要通读所有文章），得到最终的 Concept Map。

这篇文章后面的部分主要讲解如何设置标注任务，以及对于标注结果可靠性、一致性的分析，介绍了很多细节。就没仔细看了。如果想更好地利用廉价的人工标注（区别于专家标注），应该能从本文中找到不少启发。

## Fine Grained Citation Span for References in Wikipedia

兴趣点：Wikipedia

## Learning Generic Sentence Representations Using Convolutional Neural Networks

兴趣点：Sentence Representations

## MinIE: Minimizing Facts in Open Information Extraction

兴趣点：Open IE

## Multi-Grained Chinese Word Segmentation

兴趣点： Multi-Grained

## Entity Linking via Joint Encoding of Types, Descriptions, and Context

兴趣点：Entity Linking, Types

## Neural Semantic Parsing with Type Constraints for Semi-Structured Tables

兴趣点：Type Constraints

这篇文章设计了一个端到端的神经网络模型，来处理基于维基百科表格的问答任务。网络结构比较复杂，大致上是一个基于 BiLSTM 的 encoder-decoder 架构，对 entity 进行 embedding，其中包括来了 entity linking （这是文章声称的相比前人的重要改进）以及 entity 的类型信息。输出是某种考虑类别的形式语言，文章声称的第二个贡献是，在生成输出语言的时候不需要添加隐变量。然而没太多背景知识，不知道这个语言如何转化为最终的答案。

数据集用了 WikiTableQuestions，一万多训练数据和四千条测试数据，单个模型性能可以到 43.3% accuracy。文章提到有个基于 Freebase 的 QA 数据集，样例更多而且涉及 domain 更广，但问题太简单所以没有采用。

在错误分析中，文章提到几种大的错误类别：(1) 从若干选项中选一个答案，比如 “Who had more silvers, Colombia or The Bahamas”，我猜可能是因为类别一样的情况确实比较难；(2) Entity linking 错误，这个没办法。其他还有些错误原因，比如答案只是一个 Cell 内容的一部分，还有一些没太看懂的原因。

## End-to-end Neural Coreference Resolution

兴趣点：Coreference Resolution

## Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension

兴趣点：Xianpei Han

## Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach

兴趣点：Relation Extraction, Jiawei Han

## Shortest-Path Graph Kernels for Document Similarity

兴趣点：Document Similarity

## Learning to select data for transfer learning with Bayesian Optimization

兴趣点：Transfer learning


## Entity Linking for Queries by Searching Wikipedia Sentences

兴趣点：Entity Linking, Wikipedia

## Identifying Semantic Edit Intentions from Revisions in Wikipedia

兴趣点：Wikipedia Revisions

作者 [Diyi Yang](http://www.cs.cmu.edu/~diyiy/) 在 ICWSM 2016 上还发过一篇相关的文章 *Who does What: Editor Role Identification in Wikipedia*，两篇文章应该连在一起看。内容领域不太熟悉，感觉应该属于 Social Computing 的范畴，大致扫了一眼，以后需要还可以详细读。在 ICWSM 2016  的那篇文章里，作者延伸了前人对于维基百科不同编辑者的角色的分类，为各种角色下了非常直观的定义，并且跟不同的编辑行为联系在一起，构建分类器来判断编辑者所属的角色。在 EMNLP 2017 的这篇文章里，作者提出 revision 是有意图的，并且构建数据集和模型来对每一个 revision 的意图进行分类。这两篇文章分别从编辑者和编辑行为的角度出发，探讨了关于维护维基百科文章质量、新贡献者留存等问题。

## Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics

兴趣点：Word Representations





